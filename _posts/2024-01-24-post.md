---
title: "Create Python development environment in Docker - a step by step guide for Windows"
date: 2024-01-24
---



You know what really grinds my gears (Family Guy pun intended - great series)?!


When I work on multiple open-source projects and suddenly one update makes a portion of them not working.


Have you ever experienced of those symptoms after software or package update:
- functions started to return unknown earlier warnings / errors
- some programs give back different results on same data
- your old projects stopped working entirely


There is a distinct feeling, when you procrastinate on a project for a long time, then one day, bored to death, you watch a ton of motivational YouTube videos & finally decide to go back to it. You execute the code, which months ago was working fine, and then, bam! Error. Research conducted by me on a sample size of 1 (me) proves that it increases chance of dropping the project by 47,63%. 


If this happened to you, and it's rather a question of when and not if, I feel for you. But you musn't worry. Visual Studio Code + Docker Desktop might be just the right cure for you.


Hop on! It will take some time to explain!


Any comments, remarks, questions - feel free to contact me at [demistyfAI@gmail.com](mailto:demistyfai@gmail.com) 
![Robot Reading a book in a library](../../../assets/images/001P_01IMG.png)

## A little bit of history (and a personal touch)


I consider myself a recovering lazy person. Throughout my life I have been living in a spiral of periods of excessive activity (sports, reading or partying) mixed with periods of numbness (playing games whole day, watching series all day, watching that one last video of cat riding through a rainbow at the end of the Internet). That changed when I introduced 2 elements to my daily routine: structure and planned small achievements. But that's a story for another time. 


One of artifacts that I have from such periods of numbness is that I have never finished my master's thesis (thankfully I have my bachelor's degree at least). Actually twice I came close. In 2015 when I was first finishing my master's courses I became eligible to write a masters thesis. But I didn't do anything except thinking of a title. Then I moved overseas (3.5 years in England, 0.5 years in Indonesia) and didn't think about it a lot, but unfinished business hanged around my neck like an albatross. I came back to my country (Poland) in 2019 and around 2020 I decided that I will take master's courses again. And so I did - I switched to a slightly different type of degree within Economics department, had to pass around 15 different exams, and in 2022 ended up in the same scenario that I had in 2015. I had to write my master's thesis. Obviously it would be just too simple if I would write it immediately then. So I started to work on it just in 2023. Small steps - every day for 30 min (again, story for another time).


Until October everything was going fine - I got 30 pages written in LaTeX. You probably picked up already that I like to make things more difficult than they should be. Or I like ambitious tasks. Or both. It depends.). At the end of October I enrolled to a very labour-intensive AI Development course - which completely devoured 5 weeks of my time (but highly recommended! You can find it here, though it's in Polish - [AI DEVS](https://www.aidevs.pl){:target="_blank"}. During the course to utilize Python OpenAI package properly I updated my Python version from 3.9 to 3.12. When I finished the course and returned in glory - I decided to resume working on my thesis. 


Then it happened. The horror. The code that I was writing for the empirical analysis part of my thesis stopped working. Not only that - the main package for portfolio optimization PyPortfolioOpt, which is substantial to empirical part of my thesis, is at the moment not compatible with Python 3.12. What the hell!?!? Why this cruel & ungodly punishment is being brought upon me? For couple of days I tried to restore everything to the same place (fortunately I have requirements.txt file with versions of packages used in the project. Good practice, highly recommend generating ones in your programming projects), but it was just too much work and I was too frustrated. 


I like to think that I am very unique, so there shouldn't be more than 100 million people exactly like me in the world. And because I am so unique, probably thousands (if not more) of people over the world have similar software version dependency problems. There is actually a huge software company (or two - if we consider Microsoft's Visual Studio Code as the second one. Microsoft rings a bell, right?) that address this issue. Suspense music. Here comes Docker. 


There are obviously a lot of alternatives for Docker & Visual Studio Code - but let's not overcomplicate.

![Robot looking at two clearly not matching puzzles](../../../assets/images/001P_02IMG.png)

## Docker Desktop and Dev Containers to the rescue (for Windows, I plan to pick up Linux somewhere along the lines)


I could explain what is Docker and what is Visual Studio Code, but it's better if you read it on their website. If you don't like what you find there - that means this post is not for you.


So, let's work on what steps we need to take to make the magic happen.

### I. Install necessary software

Download & install those bad-boys:  
1. [Docker Desktop](https://www.docker.com/products/docker-desktop/){:target="_blank"}  
2. [Visual Studio Code](https://code.visualstudio.com/){:target="_blank"}  


### II. Create a folder for your container


Let's violate all of the terms of Geneva Conventions and for the sake of this post directly create your folder on your C: drive. 


```
C:\AwesomeFolder\KickAssContainer
```


### III. Create Dockerfile


Dockerfile is needed (at least to my current knowledge) to create your container. It contains instructions telling Docker Desktop "how" your container should look like.


Warning: filename has to be Dockerfile (no extension; case sensitive; you can create it Via notepad / Visual Studio Code / Notepad ++). Otherwise Docker won't use it.


My example of Dockerfile contents:
```
# Base image - for python environments mostly Python
FROM python:3.9-slim

# set the working directory
WORKDIR /code

# install dependencies
COPY ./requirements.txt ./

RUN pip install PyPortfolioOpt  && \
    pip install --no-cache-dir --upgrade -r requirements.txt

# copy the src to the folder
COPY ./src ./src
```


What's happening here? Let's explain step by step:


| Command | Explanation |
| ---- | ---- |
| FROM python:3.9-slim | install Python Image. List of python images available here: [python images](https://hub.docker.com/_/python){:target="_blank"} |
| WORKDIR /code | folder name on your container with files that you will want to execute on that container |
| COPY /.requirements.txt ./ | this command will copy requirements.txt file (containing version of all your Python libraries to install on the container) to your WORKDIR |
| RUN pip install PyPortfolioOpt Â && \ pip install --no-cache-dir --upgrade -r requirements.txt | this is a tricky one. Using "\" and && allows Docker to execute multiple commands in the environment one after another. For package installation we use pip, which is a Python package installer ([pypi webpage](https://pypi.org/project/pip/){:target="_blank"}). Firstly, PIP will install specific package PyPortfolioOpt (huge shoutout to Robert Martin, who is the main developer of this package. You can check the package documentation here: [PyPortfolioOpt](https://pyportfolioopt.readthedocs.io/en/latest/UserGuide.html){:target="_blank"} and Robert's website here: [Reasonable deviations](https://reasonabledeviations.com/){:target="_blank"}. Why do we need to call it like that? Because unlike most other packages that we have in our requirements file this package have different alias (PyPortfolioOpt) in pip and different while calling/installing the package to your Python instance (pypfopt). And if that's the case for some reason you have to do this workaround to install the package properly. If you find this not precise enough and have more knowledge, please drop me a message and I will happily learn more ;).<br><br>Secondly, you want to install all packages from requirements file, where options no-cache-dir prevents pip from storing additional installation files and source files on your container (you want to keep Docker image as small as possible). The "-r" command points out that next string will be pointing out to a requirements file (requirements.txt in our case). |
| COPY ./src ./src | Copy the "src" folder to our container. Having all your project codes & files in  "src" project is a common practice. |


### IV. Create docker-compose.yml


You can read about what is YAML here: [YAML Wikipedia](https://en.wikipedia.org/wiki/YAML){:target="_blank"} .Basically Docker will use it as set of commands for the container.


Our docker-compose.yml (you can also create this file in VS Code, notepad++ etc.; it's case sensitive and just save the file as .yml extension) file will look as this:
```
services:
    dev_env:
        build: .
        container_name: docker-python
        command: sleep infinity
        volumes:
            - .:/code
```


What are we telling Docker to do here?

| Command | Explanation |
| ---- | ---- |
| services: | list of services that we want Docker to run on our container |
| dev_env: | user-defined name of service. I want to have a development environment, that's why I used dev_name. You want to notice that this is part of services, so that's why we keep indentation. |
| build: . | dot informs that we have a DockerFile in the same folder as docker-compose.yml file and this will be used to create our container |
| container_name: docker-python | user-defined name of container. Should be unique and meaningful |
| command: sleep infinity | command specifically used (but not always) for debugging and dev environments. Good containers are small in size and carry out only a set of specialized instructions. After those instructions are done - container closes with exit code 0 ("container exited normally" - there are no more instructions to execute). Our case is different - we want to have a live Python development environment, where we can play around for unspecified amount of time. To achieve that - we ask container to "sleep" indefinitely. That way it will be in use until we specifically command the container to shut down. <br><br>**Warning:** While this command is useful in our case it might cause trouble in a lot of different cases. Containers execute commands in order - that means that if you build a multi-service container and you ask it to wait indefinitely before executing some other instructions (like calling a database service) - it might never finish. Be mindful of that. |
| volumes: .:/code | volume is a great Docker concept that allows us to share resources across containers and machine that creates containers. This command basically means that our work directory (as specified in section [[#III. Create Dockerfile]]) will be shared across your personal computer and container. So in practical terms: whatever change you will do to your files and codes in your container -> it gets saved back to original drive location (in our case C:\AwesomeFolder\KickAssContainer) |


### V. Requirements file

This is file containg all packages and their versions to be installed on your container environment. This is crucial for dependency management - if you specify wrong versions here, you might have problems with code development.

If you do not know how to create requirement.txt file, you can look it up in those places (I use session-info package):
1. [session info package](https://pypi.org/project/session-info/){:target="_blank"}
2. [pipreqs package](https://pypi.org/project/pipreqs/){:target="_blank"}
3. [pip freeze cmd](https://www.geeksforgeeks.org/how-to-create-requirements-txt-file-in-python/){:target="_blank"}

In my project requirements.txt file looks as below

```
matplotlib==3.6.3
mplfinance==0.12.9b7
numpy==1.24.1
pandas==1.5.3
scipy==1.10.0
session_info==1.0.0
IPython==8.8.0
jupyter_client==7.4.9
jupyter_core==4.11.1
jupyterlab==3.4.4
notebook==6.4.12
```

You might notice that I don't have PyPortfolioOpt specified here. That's because I directly ask pip to install this package in [[#III. Create Dockerfile]] section.


What you can see in the file is that we specify strong equality - which means that pip will install exactly those specified versions of packages. You can specify greater or equal versions using ">=" or compatible versions using "~=" (to be honest, never tried this one).


From matplotlib to session_info those are additional packages. Below that IPython through notebook are versions of Jupyter Notebook packages. You don't have to necessarily specify those, but session-info package has this option and I personally like to be more safe than sorry.


So overall our KickAssContainer folder contents looks like this:

![Contents of KickAssContainer folder](../../../assets/images/001P_03IMG.png)


### VI. Start your container


Yet another program to start and adventure to survive! Now that we have our container setup configured in Docker files, we can start our container. In order to do that we will have to open [Windows PowerShell](https://learn.microsoft.com/en-us/powershell/scripting/overview){:target="_blank"} (preferably with administrator privileges - so run as Administrator).


Now we will execute couple of commands. 
**Warning:**  In order for that to work you have to have Docker Desktop launched (don't worry if you open your desktop shortcut and it doesn't pop-up on main screen. Docker likes to hide in hidden icons of system tray)

```
cd C:\AwesomeFolder\KickAssContainer
ls
docker-compose up -d
```


Below screen bears fruits of our commands:


![Contents of PowerShell](../../../assets/images/001P_04IMG.png)


What happened?

| Command | Explanation |
| ---- | ---- |
| cd C:\AwesomeFolder\KickAssContainer | cd is short for "change directory". Changed directory to our containers directory |
| ls | short for list. Listed files in the directory to make sure that you are in the right directory. <br><br>**Spoiler alert:** you are. |
| docker-compose up -d | creating our container from docker-compose.yml file. This provides a substantial log (at least for the first time) covering all steps necessary to launch specified container. Option -d stands for detached - post executing container composing it will allow you to execute other commands in PowerShell. Without this option Container would block PowerShell and you would not be able to do anything until you specifically shut the container down using **ctrl + c** shortcut. |


We can see from the image that container build lasted 66,2 seconds on my laptop, most of which was packages installation & pip upgrade. This is probably the place, where more advanced Docker users can make the container lighter and faster.


Is there any proof of container up and running? Yes there is, please find this screen from Docker Desktop:
![Docker Desktop docker-python container started](../../../assets/images/001P_05IMG.png)


Now that we have our container we can start learning how to use it.

### V. Develop code in Visual Studio Code


You are getting close to coding in on your development environment now.


First, we need to open Visual Studio Code (my screenshots will be dark, because my soul is dark) and install some extensions.

![Docker Desktop docker-python container started](../../../assets/images/001P_06IMG.jpg)


So:
1. Go to "extensions" panel
2. Type whatever extension you need in search box
3. Install (on my screen button says "uninstall", because I have this extension already installed)


Necessary extensions to be installed that way: Docker & Dev Containers.


List of extensions that I am using currently:
- autopep8 - formatting support for Python
- Dev Containers - support containers on local machine
- Docker - support for Docker
- Github Copilot - paid AI code-along assistant
- Jupyter - for jupyter notebook support (interactive programming)
- Pylance - language support for Python
- Python - my programming language


It time to switch to the virtual machine:

![Docker Desktop docker-python container started](../../../assets/images/001P_07IMG.png)

1. On the bottom left side of your VS Code interface click on "><" icon saying "Open a Remote Window"
2. You will see a list in command panel. Select "Attach to running container"
3. Select "docker-python" container
4. A wild VS Code window should appear (Pokemon GameBoy game reference for older players ;) )


If you did everything correctly you should see something like this on the bottom left side of the interface.


![Docker Desktop docker-python container started](../../../assets/images/001P_08IMG.png)


Ok, Neo, you're in (again references for old people)! 


Now it's time to make some noise.


You'll need to install extensions on your VS Code Container in order to interpret Python correctly. While to my best knowledge (at least so far), this is manual, you need to do it only once.


You do it by going to the "Extensions" tab and confirming installation with "Install in container (...)" button per required extension (at least Jupyter and Python).


![Install extensions in container](../../../assets/images/001P_09IMG.png)

Now go to "File" -> "New File" (or shortcut: **ctrl + alt + win key + n**) and create a new jupyter notebook.


![Create new jupyter notebook](../../../assets/images/001P_10IMG.png)


Now you can test if your Python environment is working. You need to make sure that you have a Python kernel enabled to the compiling.


![Select python kernel](../../../assets/images/001P_11IMG.png)


I will execute some simple code:
```
import numpy as np
import pandas as pd
import pypfopt

print("Hello World")
print(2+5)
print('Wow this actually worked! You actually can trust strangers on the internet ;)....... I think')
```


And this are the results:
![Compilation results](../../../assets/images/001P_12IMG.png)


**It's working! It's working!** 


![Evil robot laughing yet surrounded by sweet kitten](../../../assets/images/001P_13IMG.png)

### VI. Saving your work and closing container


Now we can save our work. 


If you go to "File" -> "Save File" (or just use shortcut: **ctrl + S**) you will see root folder of your container.  But not only. Your beautiful work directory "code" is also there, hidden in plain sight. 


![Save file view in container](../../../assets/images/001P_14IMG.png)


Now you are in your volume folder "code" - which is a shared folder between your PC and container. Whatever you save here, stays safe on your hard drive after container is closed / removed.


![VS Code container volume folder contents](../../../assets/images/001P_15IMG.png)


To learn proper file management techniques and to keep your file structure tidy save your notebook in "src" folder. I propose file name as something along the lines "001_testContainer.ipynb".


**Done!**


Now you can close you Visual Studio Code and move to PowerShell console window.


Commands that you want to execute are (and you have to be in your C:\AwesomeFolder\KickAssContainer folder to execute them properly. If you moved, navigate again with cd command):
```
docker ps
docker compose-down
docker ps
```


You will see something like that in the console.


![PowerShell taking the container down](../../../assets/images/001P_16IMG.png)

Commands go as follow:

| Command | Explanation |
| ---- | ---- |
| docker ps | checks if there are any containers up & running. We can see that docker-python is up & well |
| docker compose-down | takes the container down |
| docker ps | checks if there are any containers up again. Returned list is null, so we closed the container succesfully |


Now you can close PowerShell and DockerDesktop. One thing remaining is to check contents of C:\\AwesomeFolder\\KickAssContainer\\src . Let's take a peek:

![src folder on your hard drive](../../../assets/images/001P_17IMG.png)


Your work is done! Congratulations!

### VII. Conclusion


Now you are ready to work in your own development environment. 


Keep in mind what we are achieving here:
1. You are managing your containers separately, that means that you can work on separate projects using different versions of same software / packages (isolation)
2. You don't need to worry about updates new versions that are compatible with your current build (easy dependency management)
3. You can easily share your projects on github or other tools along with requirements.txt file and docker files for other users to easily re-create your results (reproducibility)
4. More advanced docker users can make their Docker containers extra light to perform only necessary tasks (efficient resource utilization)

Having that in mind, have a look at 1 more useful PowerShell commands for Docker:
```
docker-compose up --build -d
```

Whenever you update your Docker files or requirements file it will be useful to rebuild the container. That's what's this command is for. 

Now you are ready to sail through the container sea. I wish you luck!

![Pirate cat on a container ship](../../../assets/images/001P_18IMG.png)

P.S. : If you have any questions, comments - please feel free to drop me an e-mail to [demistyfAI@gmail.com](mailto:demistyfai@gmail.com) 


P.S. 2: I would like to extend my gratitude to Patrick Loeber, who recorded a video with similar tutorial for Docker on YouTube. This was a huge inspiration (and starting point) for my material. You can find the video [here](https://www.youtube.com/watch?v=6OxqiEeCvMI){:target="blank"}


P.S. 3: You can find Github with necessary files used for this tutorial on my [Github](https://github.com/TGusciora/001_Post_KickAssContainer){:target="blank"}. Be mindful that you will have to copy repository contents to "C:\AwesomeFolder\KickAssContainer" to make codes working.